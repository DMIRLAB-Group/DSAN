2021-Oct-11 11:12 [INFO ] Namespace(data_dir='dataset/data/', dropout_rate=0.75, l2_loss_weight=1e-05, lr=0.0001, rec_loss_weight=1.0, result='result', seed=4, src='kitchen', tgt='electronics', trans_class_weight=0.0005, z_hidden_size=4096)
2021-Oct-11 11:12 [INFO ] NumExpr defaulting to 8 threads.
2021-Oct-11 11:12 [WARNI] From /home/lizijian/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2021-Oct-11 11:12 [WARNI] From dsan.py:110: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dropout instead.
2021-Oct-11 11:12 [WARNI] From /home/lizijian/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
2021-Oct-11 11:12 [WARNI] From /home/lizijian/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
2021-Oct-11 11:12 [INFO ] global_step:0, batch_total_loss:36.746380	, batch_domain_loss:0.816246	, batch_label_loss:1.158329,	 batch_rec_loss:34.749565 	 batch_trans_class_loss:2.248753
target_label_accuracy:0.499560, lr:0.000100, L:0.150000, best result:0.499560
2021-Oct-11 11:12 [INFO ] global_step:100, batch_total_loss:13.413868	, batch_domain_loss:0.717782	, batch_label_loss:0.729642,	 batch_rec_loss:11.948362 	 batch_trans_class_loss:1.429582
target_label_accuracy:0.759021, lr:0.000100, L:0.150000, best result:0.759021
2021-Oct-11 11:12 [INFO ] global_step:200, batch_total_loss:12.571877	, batch_domain_loss:0.710731	, batch_label_loss:0.609052,	 batch_rec_loss:11.234173 	 batch_trans_class_loss:1.407330
target_label_accuracy:0.811477, lr:0.000100, L:0.150000, best result:0.811477
2021-Oct-11 11:12 [INFO ] global_step:300, batch_total_loss:12.186961	, batch_domain_loss:0.707327	, batch_label_loss:0.477672,	 batch_rec_loss:10.984209 	 batch_trans_class_loss:1.381106
target_label_accuracy:0.835592, lr:0.000100, L:0.150000, best result:0.835592
2021-Oct-11 11:12 [INFO ] global_step:400, batch_total_loss:11.949944	, batch_domain_loss:0.705517	, batch_label_loss:0.378060,	 batch_rec_loss:10.848851 	 batch_trans_class_loss:1.338695
target_label_accuracy:0.844746, lr:0.000100, L:0.150000, best result:0.844746
2021-Oct-11 11:12 [INFO ] global_step:500, batch_total_loss:11.797118	, batch_domain_loss:0.703041	, batch_label_loss:0.309523,	 batch_rec_loss:10.767244 	 batch_trans_class_loss:1.300923
target_label_accuracy:0.846682, lr:0.000100, L:0.150000, best result:0.846682
2021-Oct-11 11:12 [INFO ] global_step:600, batch_total_loss:11.683815	, batch_domain_loss:0.699521	, batch_label_loss:0.261170,	 batch_rec_loss:10.705969 	 batch_trans_class_loss:1.272545
target_label_accuracy:0.847210, lr:0.000100, L:0.150000, best result:0.847210
2021-Oct-11 11:12 [INFO ] global_step:700, batch_total_loss:11.600603	, batch_domain_loss:0.695029	, batch_label_loss:0.225622,	 batch_rec_loss:10.662938 	 batch_trans_class_loss:1.246028
target_label_accuracy:0.847034, lr:0.000100, L:0.150000, best result:0.847210
2021-Oct-11 11:12 [INFO ] global_step:800, batch_total_loss:11.536043	, batch_domain_loss:0.690847	, batch_label_loss:0.198569,	 batch_rec_loss:10.629721 	 batch_trans_class_loss:1.225666
target_label_accuracy:0.847738, lr:0.000100, L:0.150000, best result:0.847738
2021-Oct-11 11:13 [INFO ] global_step:900, batch_total_loss:11.483011	, batch_domain_loss:0.688070	, batch_label_loss:0.177440,	 batch_rec_loss:10.600691 	 batch_trans_class_loss:1.207471
target_label_accuracy:0.848970, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1000, batch_total_loss:11.440883	, batch_domain_loss:0.686713	, batch_label_loss:0.160597,	 batch_rec_loss:10.576843 	 batch_trans_class_loss:1.192220
target_label_accuracy:0.847386, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1100, batch_total_loss:11.405982	, batch_domain_loss:0.686793	, batch_label_loss:0.146579,	 batch_rec_loss:10.555949 	 batch_trans_class_loss:1.179094
target_label_accuracy:0.843513, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1200, batch_total_loss:11.378369	, batch_domain_loss:0.687554	, batch_label_loss:0.134898,	 batch_rec_loss:10.539314 	 batch_trans_class_loss:1.167924
target_label_accuracy:0.838937, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1300, batch_total_loss:11.356492	, batch_domain_loss:0.688915	, batch_label_loss:0.124902,	 batch_rec_loss:10.526119 	 batch_trans_class_loss:1.158697
target_label_accuracy:0.839289, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1400, batch_total_loss:11.334913	, batch_domain_loss:0.690406	, batch_label_loss:0.116374,	 batch_rec_loss:10.511619 	 batch_trans_class_loss:1.150576
target_label_accuracy:0.839113, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1500, batch_total_loss:11.317210	, batch_domain_loss:0.691746	, batch_label_loss:0.109050,	 batch_rec_loss:10.499935 	 batch_trans_class_loss:1.143589
target_label_accuracy:0.840169, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1600, batch_total_loss:11.300701	, batch_domain_loss:0.692395	, batch_label_loss:0.102526,	 batch_rec_loss:10.489327 	 batch_trans_class_loss:1.138564
target_label_accuracy:0.839113, lr:0.000100, L:0.150000, best result:0.848970
2021-Oct-11 11:13 [INFO ] global_step:1700, batch_total_loss:11.284924	, batch_domain_loss:0.692666	, batch_label_loss:0.096761,	 batch_rec_loss:10.479075 	 batch_trans_class_loss:1.132486
target_label_accuracy:0.839289, lr:0.000100, L:0.150000, best result:0.848970
